name: UI Tests

on:
  workflow_dispatch:
    inputs:
      test-file:
        description: 'Test file to run'
        required: false
        default: 'tests/ui/registration/test_registration_stability.py'
      pytest-args:
        description: 'Additional pytest arguments'
        required: false
        default: '-v --tb=short'
      environment:
        description: 'Test environment'
        required: true
        type: choice
        options:
          - pgp_sit
          - kansas_staging
          - catalyst_sit
          - phoenix_staging
        default: 'pgp_sit'
      device:
        description: 'Browser/Device'
        required: true
        type: choice
        options:
          - chrome
          - firefox
          - safari
          - desktop
          - mobile
          - tablet
        default: 'chrome'
      scenario:
        description: 'Test scenario'
        required: true
        type: choice
        options:
          - all
          - bonus
          - dgs
          - instants
          - deposits
          - claims
          - withdrawals
          - registration
          - risk
        default: 'all'

env:
  PYTHON_VERSION: '3.11'
  PYTHONPATH: ${{ github.workspace }}
  PYTHONWARNINGS: ignore
  ENVIRONMENT: ${{ github.event.inputs.environment || 'pgp_sit' }}
  DEVICE: ${{ github.event.inputs.device || 'chrome' }}
  SCENARIO: ${{ github.event.inputs.scenario || 'all' }}

jobs:
  ui-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Setup test environment
        uses: ./.github/actions/setup-environment-fast
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Run UI tests
        id: run-tests
        uses: ./.github/actions/run-ui-tests
        with:
          test-file: ${{ github.event.inputs.test-file || 'tests/ui/registration/test_registration_stability.py' }}
          pytest-args: ${{ github.event.inputs.pytest-args || '-v --tb=short' }}
          scenario: ${{ github.event.inputs.scenario || 'all' }}
        continue-on-error: true

      - name: Upload test videos
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-videos-${{ github.run_number }}
          path: test-results/videos/
          retention-days: 7

      - name: Upload screenshots
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-screenshots-${{ github.run_number }}
          path: test-results/screenshots/
          retention-days: 7

      - name: Upload test logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-logs-${{ github.run_number }}
          path: test-results/logs/
          retention-days: 14

      - name: Upload test report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-report-${{ github.run_number }}
          path: test-results/report.html
          retention-days: 14

      - name: Send Teams notification
        uses: ./.github/actions/teams-notification
        if: always()
        with:
          webhook-url: ${{ secrets.TEAMS_WEBHOOK_URL }}
          test-result: ${{ steps.run-tests.outputs.test-result }}
          test-summary: ${{ steps.run-tests.outputs.test-summary }}
          build-url: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          video-url: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          logs-url: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          total-tests: ${{ steps.run-tests.outputs.total-tests }}
          passed-tests: ${{ steps.run-tests.outputs.passed-tests }}
          failed-tests: ${{ steps.run-tests.outputs.failed-tests }}
          environment: ${{ env.ENVIRONMENT }}
          device: ${{ env.DEVICE }}
          scenario: ${{ env.SCENARIO }}

      - name: Fail job if tests failed
        if: steps.run-tests.outputs.test-result == 'failure'
        run: |
          echo "Tests failed!"
          exit 1

  test-summary:
    runs-on: ubuntu-latest
    needs: ui-tests
    if: always()
    steps:
      - name: Test Summary
        run: |
          echo "## ðŸ§ª UI Test Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Status | ${{ needs.ui-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Environment | ${{ github.event.inputs.environment || 'pgp_sit' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Device | ${{ github.event.inputs.device || 'chrome' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Scenario | ${{ github.event.inputs.scenario || 'all' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Test File | ${{ github.event.inputs.test-file || 'tests/ui/registration/test_registration_stability.py' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Run ID | ${{ github.run_id }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“¹ [Test Videos](../../actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“¸ [Screenshots](../../actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“‹ [Test Logs](../../actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“Š [HTML Report](../../actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
